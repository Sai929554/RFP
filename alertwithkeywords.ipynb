{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc80f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Authenticating with Google APIs...\n",
      "Credentials saved to token.json\n",
      "üì© Fetching emails from the past year...\n",
      "üì© Total Emails Found: 2675\n",
      "‚ùå Batch request error for message 197f3c026885d70e: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197f3c026885d70e?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197f3bfb5a9cbe1d: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197f3bfb5a9cbe1d?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197f37f499a3053b: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197f37f499a3053b?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197f37f2002f5f49: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197f37f2002f5f49?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197f37e5d2a07edd: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197f37e5d2a07edd?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197ef34a3e0756b5: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197ef34a3e0756b5?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197e9eeea06caf28: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197e9eeea06caf28?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197e9a1ee62bc0cd: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197e9a1ee62bc0cd?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197e9a06316b9937: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197e9a06316b9937?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197e47ed88e413b9: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197e47ed88e413b9?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197e47e4070e26c8: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197e47e4070e26c8?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197db81f44c4d726: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197db81f44c4d726?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d59e91ad0d9a2: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d59e91ad0d9a2?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d57bf62e5a741: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d57bf62e5a741?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d57afe19adc64: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d57afe19adc64?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d57ab31c6110a: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d57ab31c6110a?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d4b9eb353283b: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d4b9eb353283b?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d3c4aa2c88ac8: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d3c4aa2c88ac8?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d382395d6849f: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d382395d6849f?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d0825d17babcd: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d0825d17babcd?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d081c8c061d59: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d081c8c061d59?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d07da1791f9c7: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d07da1791f9c7?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d073ef18a4aeb: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d073ef18a4aeb?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d0723290a367f: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d0723290a367f?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d0719ccd04b88: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d0719ccd04b88?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d06d007a944f7: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d06d007a944f7?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197d060bcce25edb: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197d060bcce25edb?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197c993207950496: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197c993207950496?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197c98f7c4b1d60e: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197c98f7c4b1d60e?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197ac4afa66c482f: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197ac4afa66c482f?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197abf9628a11427: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197abf9628a11427?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197abf84200bbb48: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197abf84200bbb48?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197abf7fd0d5a63e: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197abf7fd0d5a63e?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197abf76842eca14: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197abf76842eca14?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a5f03ee5999bd: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a5f03ee5999bd?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a573d08c3cdda: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a573d08c3cdda?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a3238027aa3e8: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a3238027aa3e8?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a09c6ed05006a: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a09c6ed05006a?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a09484e680d68: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a09484e680d68?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a0846978f5e1e: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a0846978f5e1e?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a083592bddff3: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a083592bddff3?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a077ce93daea8: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a077ce93daea8?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a050820c565bb: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a050820c565bb?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a04fccb7b8225: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a04fccb7b8225?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a03cd9812a030: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a03cd9812a030?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a0366f559f548: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a0366f559f548?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 197a035860098fb2: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/197a035860098fb2?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 1979ced12bbbaf4f: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/1979ced12bbbaf4f?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 1979ccfe86150052: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/1979ccfe86150052?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 1979ccfe4ecc35df: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/1979ccfe4ecc35df?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n",
      "‚ùå Batch request error for message 1979ccf17dcf19cc: <HttpError 429 when requesting https://gmail.googleapis.com/gmail/v1/users/me/messages/1979ccf17dcf19cc?format=metadata&metadataHeaders=From&metadataHeaders=Subject&alt=json returned \"Too many concurrent requests for user.\". Details: \"[{'message': 'Too many concurrent requests for user.', 'domain': 'global', 'reason': 'rateLimitExceeded'}]\">\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1286\u001b[0m\n\u001b[0;32m   1284\u001b[0m gmail_service, calendar_service \u001b[38;5;241m=\u001b[39m authenticate_google()\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müì© Fetching emails from the past year...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1286\u001b[0m \u001b[43mlist_all_emails\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgmail_service\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalendar_service\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚è∞ Starting alert scheduler...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1288\u001b[0m run_scheduler(gmail_service, calendar_service)\n",
      "Cell \u001b[1;32mIn[1], line 536\u001b[0m, in \u001b[0;36mlist_all_emails\u001b[1;34m(gmail_service, calendar_service, run_alerts)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_requests \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m:  \u001b[38;5;66;03m# Further reduced batch size\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     execute_batch_with_retry(batch)\n\u001b[1;32m--> 536\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Increased delay\u001b[39;00m\n\u001b[0;32m    537\u001b[0m     batch \u001b[38;5;241m=\u001b[39m gmail_service\u001b[38;5;241m.\u001b[39mnew_batch_http_request(callback\u001b[38;5;241m=\u001b[39mbatch_callback)\n\u001b[0;32m    538\u001b[0m     batch_requests \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import base64\n",
    "import logging\n",
    "import time\n",
    "import os.path\n",
    "import json\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import BatchHttpRequest\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple\n",
    "import pytz\n",
    "from dateutil.parser import parse as parse_date\n",
    "import email\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from functools import wraps\n",
    "import schedule\n",
    "import threading\n",
    "import http.server\n",
    "import socketserver\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='date_parsing.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('google_auth_oauthlib').setLevel(logging.DEBUG)\n",
    "\n",
    "# Updated SCOPES to include Gmail send permission\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/calendar.readonly',\n",
    "    'https://www.googleapis.com/auth/gmail.send'\n",
    "]\n",
    "\n",
    "# Manually defined list of email addresses for alerts\n",
    "ALERT_RECIPIENTS = [\n",
    "    'andrew@iitlabs.com',\n",
    "    # Add more email addresses as needed\n",
    "]\n",
    "\n",
    "# Manually defined time for daily alerts (24-hour format, e.g., \"09:30\" for 9:30 AM)\n",
    "ALERT_TIME = \"18:40\"  # Updated to match your email timestamp\n",
    "\n",
    "# Port for the HTTP server\n",
    "HTTP_PORT = 8000\n",
    "\n",
    "# HTML content for the interactive UI\n",
    "HTML_CONTENT = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>RFP Opportunities Dashboard</title>\n",
    "    <script src=\"https://cdn.tailwindcss.com\"></script>\n",
    "    <link rel=\"stylesheet\" href=\"https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css\">\n",
    "    <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
    "    <script src=\"https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js\"></script>\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; }\n",
    "        .dataTables_wrapper .dataTables_filter input {\n",
    "            border: 1px solid #e5e7eb;\n",
    "            padding: 0.5rem;\n",
    "            border-radius: 0.375rem;\n",
    "            margin-bottom: 1rem;\n",
    "        }\n",
    "        .dataTables_wrapper .dataTables_length select {\n",
    "            border: 1px solid #e5e7eb;\n",
    "            padding: 0.5rem;\n",
    "            border-radius: 0.375rem;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body class=\"bg-gray-100\">\n",
    "    <div class=\"max-w-7xl mx-auto p-6\">\n",
    "        <h1 class=\"text-3xl font-bold mb-6\">RFP Opportunities Due Today</h1>\n",
    "        <table id=\"rfpTable\" class=\"display w-full bg-white shadow-md rounded-lg\">\n",
    "            <thead class=\"bg-gray-200\">\n",
    "                <tr>\n",
    "                    <th class=\"p-3 text-left\">Subject</th>\n",
    "                    <th class=\"p-3 text-left\">Online Link</th>\n",
    "                    <th class=\"p-3 text-left\">Due Date</th>\n",
    "                    <th class=\"p-3 text-left\">Agency</th>\n",
    "                    <th class=\"p-3 text-left\">Reference</th>\n",
    "                    <th class=\"p-3 text-left\">Contact</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "                <!-- Data will be populated dynamically -->\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        $(document).ready(function() {\n",
    "            // Initialize DataTable\n",
    "            const table = $('#rfpTable').DataTable({\n",
    "                paging: true,\n",
    "                searching: true,\n",
    "                ordering: true,\n",
    "                info: true,\n",
    "                lengthChange: true,\n",
    "                pageLength: 10,\n",
    "                columnDefs: [\n",
    "                    { width: '20%', targets: 0 },\n",
    "                    { width: '25%', targets: 1 },\n",
    "                    { width: '15%', targets: 2 },\n",
    "                    { width: '20%', targets: 3 },\n",
    "                    { width: '15%', targets: 4 },\n",
    "                    { width: '15%', targets: 5 }\n",
    "                ]\n",
    "            });\n",
    "\n",
    "            // Fetch data from JSON file\n",
    "            $.ajax({\n",
    "                url: '/rfp_due_today.json',\n",
    "                method: 'GET',\n",
    "                dataType: 'json',\n",
    "                success: function(data) {\n",
    "                    if (data && data.length > 0) {\n",
    "                        data.forEach(row => {\n",
    "                            table.row.add([\n",
    "                                row.subject,\n",
    "                                `<a href=\"${row.online_link}\" class=\"text-blue-600 hover:underline\" target=\"_blank\">View Opportunity</a>`,\n",
    "                                row.formatted_date,\n",
    "                                row.agency,\n",
    "                                row.reference,\n",
    "                                row.contact\n",
    "                            ]).draw();\n",
    "                        });\n",
    "                    } else {\n",
    "                        table.row.add([\n",
    "                            'No RFPs Due Today',\n",
    "                            '',\n",
    "                            '',\n",
    "                            '',\n",
    "                            '',\n",
    "                            ''\n",
    "                        ]).draw();\n",
    "                    }\n",
    "                },\n",
    "                error: function(xhr, status, error) {\n",
    "                    console.error('Error fetching RFP data:', error);\n",
    "                    table.row.add([\n",
    "                        'Error Loading Data',\n",
    "                        '',\n",
    "                        '',\n",
    "                        '',\n",
    "                        '',\n",
    "                        ''\n",
    "                    ]).draw();\n",
    "                }\n",
    "            });\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def retry_on_transient_error(max_attempts=3, backoff_factor=1):\n",
    "    \"\"\"Decorator to retry on transient HttpError with exponential backoff.\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            attempts = 0\n",
    "            while attempts < max_attempts:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except HttpError as e:\n",
    "                    transient_codes = {429, 500, 502, 503, 504}\n",
    "                    if e.resp.status not in transient_codes:\n",
    "                        raise\n",
    "                    attempts += 1\n",
    "                    if attempts == max_attempts:\n",
    "                        raise\n",
    "                    sleep_time = backoff_factor * (2 ** (attempts - 1))\n",
    "                    logging.warning(f\"Transient error {e.resp.status} in {func.__name__}, retrying in {sleep_time}s (attempt {attempts}/{max_attempts})\")\n",
    "                    time.sleep(sleep_time)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry_on_transient_error()\n",
    "def authenticate_google() -> tuple[build, build]:\n",
    "    \"\"\"\n",
    "    Authenticates Gmail and Calendar APIs using token-based credentials.\n",
    "    Ensures a refresh token is issued and enforces a 6-month validity by tracking creation time.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    token_path = 'token.json'\n",
    "    token_creation_time = None\n",
    "    six_months = timedelta(days=183)  # Approximate 6 months\n",
    "\n",
    "    # Load credentials from token.json if it exists\n",
    "    if os.path.exists(token_path):\n",
    "        try:\n",
    "            with open(token_path, 'r') as token_file:\n",
    "                token_data = json.load(token_file)\n",
    "            creds = Credentials.from_authorized_user_info(token_data, SCOPES)\n",
    "            token_creation_time = token_data.get('creation_time')\n",
    "            logging.info(f\"Loaded credentials from {token_path}. Refresh token present: {creds.refresh_token is not None}\")\n",
    "        except (ValueError, json.JSONDecodeError) as e:\n",
    "            logging.error(f\"Failed to load credentials from {token_path}: {e}\")\n",
    "            print(f\"Error: Invalid {token_path} file. Deleting and re-authenticating...\")\n",
    "            os.remove(token_path)\n",
    "            creds = None\n",
    "            token_creation_time = None\n",
    "\n",
    "    # Check if token is older than 6 months\n",
    "    if token_creation_time:\n",
    "        try:\n",
    "            creation_dt = datetime.fromisoformat(token_creation_time)\n",
    "            current_dt = datetime.now(pytz.UTC)\n",
    "            if current_dt - creation_dt > six_months:\n",
    "                logging.info(f\"Token is older than 6 months (created: {token_creation_time}). Forcing re-authentication.\")\n",
    "                print(\"Token expired (older than 6 months). Re-authenticating...\")\n",
    "                os.remove(token_path)\n",
    "                creds = None\n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Invalid creation_time in {token_path}: {e}. Deleting and re-authenticating...\")\n",
    "            os.remove(token_path)\n",
    "            creds = None\n",
    "\n",
    "    # Check if credentials are valid or can be refreshed\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            try:\n",
    "                creds.refresh(Request())\n",
    "                logging.info(\"Successfully refreshed access token.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to refresh token: {e}\")\n",
    "                print(f\"Error: Failed to refresh token ({e}). Re-authenticating...\")\n",
    "                if os.path.exists(token_path):\n",
    "                    os.remove(token_path)\n",
    "                creds = None\n",
    "        \n",
    "        # Run OAuth flow if no valid credentials\n",
    "        if not creds:\n",
    "            try:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file('client.json', SCOPES)\n",
    "                creds = flow.run_local_server(\n",
    "                    port=8080,\n",
    "                    access_type='offline',  # Ensure refresh token is issued\n",
    "                    prompt='consent'        # Force consent screen to get refresh token\n",
    "                )\n",
    "                logging.info(f\"OAuth flow completed. Refresh token obtained: {creds.refresh_token is not None}\")\n",
    "            except FileNotFoundError:\n",
    "                print(\"Error: 'client.json' file not found. Please download OAuth 2.0 credentials from Google Cloud Console.\")\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                print(f\"Error: OAuth flow failed: {e}. Ensure your Google account is authorized and the browser flow completes successfully.\")\n",
    "                raise\n",
    "        \n",
    "        # Save credentials with creation time\n",
    "        if creds:\n",
    "            try:\n",
    "                token_data = json.loads(creds.to_json())\n",
    "                token_data['creation_time'] = datetime.now(pytz.UTC).isoformat()  # Store creation time\n",
    "                with open(token_path, 'w') as token:\n",
    "                    json.dump(token_data, token, indent=2)\n",
    "                print(f\"Credentials saved to {token_path}\")\n",
    "                logging.info(f\"Saved credentials to {token_path}. Refresh token: {creds.refresh_token is not None}, Creation time: {token_data['creation_time']}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to save credentials to {token_path}: {e}\")\n",
    "                print(f\"Warning: Failed to save credentials to {token_path}: {e}\")\n",
    "        else:\n",
    "            print(\"Error: No valid credentials obtained from OAuth flow.\")\n",
    "            raise ValueError(\"Authentication failed: No valid credentials obtained.\")\n",
    "\n",
    "    # Build API services\n",
    "    try:\n",
    "        gmail_service = build('gmail', 'v1', credentials=creds)\n",
    "        calendar_service = build('calendar', 'v3', credentials=creds)\n",
    "        return gmail_service, calendar_service\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to build API services: {e}\")\n",
    "        raise\n",
    "\n",
    "@retry_on_transient_error()\n",
    "def send_alert_email(gmail_service: build, recipient: str, events: List[Dict]) -> None:\n",
    "    \"\"\"Sends an alert email with RFP opportunities in an HTML table.\"\"\"\n",
    "    if not events:\n",
    "        logging.info(f\"No events to send for recipient {recipient}\")\n",
    "        return\n",
    "\n",
    "    # Validate email address format\n",
    "    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    if not re.match(email_pattern, recipient):\n",
    "        logging.error(f\"Invalid recipient email address: {recipient}\")\n",
    "        print(f\"Error: Invalid recipient email address: {recipient}\")\n",
    "        return\n",
    "\n",
    "    # Create HTML body with inline CSS\n",
    "    html_body = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; margin: 0; padding: 20px; }\n",
    "            h1 { font-size: 24px; margin-bottom: 20px; }\n",
    "            table { width: 100%; border-collapse: collapse; margin-top: 10px; }\n",
    "            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n",
    "            th { background-color: #f2f2f2; font-weight: bold; }\n",
    "            a { color: #1a73e8; text-decoration: none; }\n",
    "            a:hover { text-decoration: underline; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>RFP Opportunities Due Today</h1>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>Subject</th>\n",
    "                    <th>Online Link</th>\n",
    "                    <th>Due Date</th>\n",
    "                    <th>Agency</th>\n",
    "                    <th>Reference</th>\n",
    "                    <th>Contact</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    \"\"\"\n",
    "    for event in events:\n",
    "        html_body += \"\"\"\n",
    "                <tr>\n",
    "                    <td>{subject}</td>\n",
    "                    <td><a href=\"{online_link}\">{online_link}</a></td>\n",
    "                    <td>{formatted_date}</td>\n",
    "                    <td>{agency}</td>\n",
    "                    <td>{reference}</td>\n",
    "                    <td>{contact}</td>\n",
    "                </tr>\n",
    "        \"\"\".format(\n",
    "            subject=event['subject'],\n",
    "            online_link=event['online_link'],\n",
    "            formatted_date=event['formatted_date'],\n",
    "            agency=event['agency'],\n",
    "            reference=event['reference'],\n",
    "            contact=event['contact']\n",
    "        )\n",
    "    html_body += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Create plain text fallback\n",
    "    plain_text_body = \"RFP Opportunities Due Today\\n\\n\"\n",
    "    for event in events:\n",
    "        plain_text_body += f\"Subject: {event['subject']}\\n\"\n",
    "        plain_text_body += f\"Online Link: {event['online_link']}\\n\"\n",
    "        plain_text_body += f\"Due Date: {event['formatted_date']}\\n\"\n",
    "        plain_text_body += f\"Agency: {event['agency']}\\n\"\n",
    "        plain_text_body += f\"Reference: {event['reference']}\\n\"\n",
    "        plain_text_body += f\"Contact: {event['contact']}\\n\\n\"\n",
    "\n",
    "    # Create MIME message\n",
    "    message = MIMEMultipart('alternative')\n",
    "    message['to'] = recipient\n",
    "    message['subject'] = 'RFP Opportunities Due Today'\n",
    "    message['from'] = 'me'\n",
    "\n",
    "    # Attach plain text and HTML parts\n",
    "    part1 = MIMEText(plain_text_body, 'plain')\n",
    "    part2 = MIMEText(html_body, 'html')\n",
    "    message.attach(part1)\n",
    "    message.attach(part2)\n",
    "\n",
    "    # Encode the message\n",
    "    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        message = gmail_service.users().messages().send(\n",
    "            userId='me',\n",
    "            body={'raw': raw_message}\n",
    "        ).execute()\n",
    "        logging.info(f\"Sent alert email to {recipient} with {len(events)} events\")\n",
    "        print(f\"Sent alert email to {recipient}\")\n",
    "    except HttpError as e:\n",
    "        logging.error(f\"Failed to send alert email to {recipient}: {e}\")\n",
    "        print(f\"Error: Failed to send alert email to {recipient}: {e}\")\n",
    "\n",
    "def check_and_send_alerts(gmail_service: build, active_events: List[Dict], current_date: datetime) -> None:\n",
    "    \"\"\"Checks for events due today, sends alerts, and saves to JSON.\"\"\"\n",
    "    ny_tz = pytz.timezone('America/New_York')\n",
    "    today = current_date.date()\n",
    "\n",
    "    # Find events due today\n",
    "    due_today = []\n",
    "    for event in active_events:\n",
    "        try:\n",
    "            event_date = datetime.strptime(event['formatted_date'], '%Y-%m-%d').date()\n",
    "            if event_date == today:\n",
    "                due_today.append(event)\n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Failed to parse event date {event['formatted_date']}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save due_today to JSON file\n",
    "    with open('rfp_due_today.json', 'w') as f:\n",
    "        json.dump(due_today, f, indent=2)\n",
    "    logging.info(f\"Saved {len(due_today)} events due today to rfp_due_today.json\")\n",
    "\n",
    "    if due_today:\n",
    "        logging.info(f\"Found {len(due_today)} events due today\")\n",
    "        for recipient in ALERT_RECIPIENTS:\n",
    "            send_alert_email(gmail_service, recipient, due_today)\n",
    "    else:\n",
    "        logging.info(\"No events due today\")\n",
    "\n",
    "def run_scheduler(gmail_service: build, calendar_service: build):\n",
    "    \"\"\"Runs the scheduler in a separate thread to check for alerts daily at the specified time.\"\"\"\n",
    "    def scheduler_loop():\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "            time.sleep(60)  # Check every minute\n",
    "\n",
    "    # Validate ALERT_TIME format\n",
    "    try:\n",
    "        datetime.strptime(ALERT_TIME, '%H:%M')\n",
    "    except ValueError as e:\n",
    "        error_msg = f\"Invalid ALERT_TIME format: {ALERT_TIME}. Please use HH:MM format (e.g., '09:30').\"\n",
    "        logging.error(error_msg)\n",
    "        print(f\"Error: {error_msg}\")\n",
    "        raise ValueError(error_msg)\n",
    "\n",
    "    # Schedule the alert check at the specified time daily\n",
    "    ny_tz = pytz.timezone('America/New_York')\n",
    "    schedule.every().day.at(ALERT_TIME).do(\n",
    "        lambda: list_all_emails(gmail_service, calendar_service, run_alerts=True)\n",
    "    ).timezone = ny_tz\n",
    "\n",
    "    # Start scheduler in a separate thread\n",
    "    scheduler_thread = threading.Thread(target=scheduler_loop, daemon=True)\n",
    "    scheduler_thread.start()\n",
    "    logging.info(f\"Started scheduler for daily alerts at {ALERT_TIME}\")\n",
    "    print(f\"‚è∞ Scheduler started for daily alerts at {ALERT_TIME}\")\n",
    "\n",
    "def list_all_emails(gmail_service: build, calendar_service: build, run_alerts: bool = False) -> None:\n",
    "    \"\"\"Fetches and displays emails from the inbox with categorization using batch processing.\"\"\"\n",
    "    try:\n",
    "        messages = []\n",
    "        next_page_token = None\n",
    "        google_service_count = 0\n",
    "        daily_bids_count = 0\n",
    "        api_error_count = 0\n",
    "        dedup_skip_count = 0\n",
    "        data_skip_count = 0\n",
    "\n",
    "        # Calculate date for one year ago\n",
    "        one_year_ago = datetime.now(pytz.UTC) - timedelta(days=365)\n",
    "        query = f\"after:{one_year_ago.strftime('%Y/%m/%d')}\"\n",
    "        logging.info(f\"Fetching emails with query: {query}\")\n",
    "\n",
    "        # Fetch all message IDs with retry\n",
    "        @retry_on_transient_error()\n",
    "        def fetch_messages(page_token):\n",
    "            return gmail_service.users().messages().list(\n",
    "                userId='me',\n",
    "                maxResults=1000,\n",
    "                pageToken=page_token,\n",
    "                q=query\n",
    "            ).execute()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                result = fetch_messages(next_page_token)\n",
    "                messages.extend(result.get('messages', []))\n",
    "                next_page_token = result.get('nextPageToken')\n",
    "                logging.info(f\"Fetched {len(result.get('messages', []))} messages. Next page token: {next_page_token}\")\n",
    "                if not next_page_token:\n",
    "                    break\n",
    "            except HttpError as e:\n",
    "                if e.resp.status == 403:\n",
    "                    logging.error(f\"Quota exceeded: {e}\")\n",
    "                    print(\"Error: Gmail API quota exceeded. Try again later or increase quota in Google Cloud Console.\")\n",
    "                    raise\n",
    "                raise\n",
    "\n",
    "        print(f\"üì© Total Emails Found: {len(messages)}\")\n",
    "\n",
    "        opportunities = []\n",
    "        message_data_dict = {}\n",
    "        batch_requests = 0\n",
    "        seen_link_ref_pairs = set()\n",
    "        seen_opportunities = set()\n",
    "\n",
    "        # Define batch callback function\n",
    "        def batch_callback(request_id, response, exception):\n",
    "            nonlocal api_error_count\n",
    "            if exception is not None:\n",
    "                api_error_count += 1\n",
    "                error_msg = f\"Batch request error for message {request_id}: {str(exception)}\"\n",
    "                logging.error(error_msg)\n",
    "                print(f\"‚ùå {error_msg}\")\n",
    "                message_data_dict[request_id] = {\n",
    "                    'error': error_msg\n",
    "                }\n",
    "            else:\n",
    "                message_data_dict[request_id] = response\n",
    "\n",
    "        # Retry wrapper for batch execution\n",
    "        def execute_batch_with_retry(batch, max_attempts=3, backoff_factor=1):\n",
    "            attempts = 0\n",
    "            while attempts < max_attempts:\n",
    "                try:\n",
    "                    batch.execute()\n",
    "                    return\n",
    "                except HttpError as e:\n",
    "                    if e.resp.status != 429:\n",
    "                        raise\n",
    "                    attempts += 1\n",
    "                    if attempts == max_attempts:\n",
    "                        raise\n",
    "                    sleep_time = backoff_factor * (2 ** (attempts - 1))\n",
    "                    logging.warning(f\"Rate limit error in batch execution, retrying in {sleep_time}s (attempt {attempts}/{max_attempts})\")\n",
    "                    time.sleep(sleep_time)\n",
    "\n",
    "        # First pass: Fetch headers using metadata format\n",
    "        batch = gmail_service.new_batch_http_request(callback=batch_callback)\n",
    "        for msg in messages:\n",
    "            batch.add(\n",
    "                gmail_service.users().messages().get(\n",
    "                    userId='me',\n",
    "                    id=msg['id'],\n",
    "                    format='metadata',\n",
    "                    metadataHeaders=['From', 'Subject']\n",
    "                ),\n",
    "                request_id=msg['id']\n",
    "            )\n",
    "            batch_requests += 1\n",
    "            if batch_requests >= 25:  # Further reduced batch size\n",
    "                execute_batch_with_retry(batch)\n",
    "                time.sleep(1.0)  # Increased delay\n",
    "                batch = gmail_service.new_batch_http_request(callback=batch_callback)\n",
    "                batch_requests = 0\n",
    "        if batch_requests > 0:\n",
    "            execute_batch_with_retry(batch)\n",
    "\n",
    "        # Process headers and identify relevant messages\n",
    "        relevant_message_ids = []\n",
    "        for msg in messages:\n",
    "            msg_data = message_data_dict.get(msg['id'], {})\n",
    "            if 'error' in msg_data:\n",
    "                opportunities.append({\n",
    "                    'subject': \"No Subject\",\n",
    "                    'online_link': \"NOT AVAILABLE\",\n",
    "                    'event_date': \"NOT AVAILABLE\",\n",
    "                    'agency': \"NOT AVAILABLE\",\n",
    "                    'reference': \"NOT AVAILABLE\",\n",
    "                    'contact': \"NOT AVAILABLE\",\n",
    "                    'raw_subject': \"No Subject\",\n",
    "                    'extraction_error': msg_data['error']\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            headers = msg_data.get('payload', {}).get('headers', [])\n",
    "            if is_google_service_email(headers):\n",
    "                google_service_count += 1\n",
    "                continue\n",
    "            if is_daily_bids_alert_email(headers):\n",
    "                daily_bids_count += 1\n",
    "                continue\n",
    "            relevant_message_ids.append(msg['id'])\n",
    "\n",
    "        # Second pass: Fetch full email data for relevant messages\n",
    "        batch = gmail_service.new_batch_http_request(callback=batch_callback)\n",
    "        batch_requests = 0\n",
    "        message_data_dict.clear()\n",
    "\n",
    "        for i, msg_id in enumerate(relevant_message_ids, 1):\n",
    "            print(f\"\\rüîç Processing email {i}/{len(relevant_message_ids)}...\", end=\"\", flush=True)\n",
    "            batch.add(\n",
    "                gmail_service.users().messages().get(\n",
    "                    userId='me',\n",
    "                    id=msg_id,\n",
    "                    format='full'\n",
    "                ),\n",
    "                request_id=msg_id\n",
    "            )\n",
    "            batch_requests += 1\n",
    "            if batch_requests >= 25:  # Further reduced batch size\n",
    "                execute_batch_with_retry(batch)\n",
    "                time.sleep(1.0)  # Increased delay\n",
    "                batch = gmail_service.new_batch_http_request(callback=batch_callback)\n",
    "                batch_requests = 0\n",
    "        if batch_requests > 0:\n",
    "            execute_batch_with_retry(batch)\n",
    "\n",
    "        # Process fetched full emails\n",
    "        for i, msg_id in enumerate(relevant_message_ids, 1):\n",
    "            msg_data = message_data_dict.get(msg_id, {})\n",
    "            if 'error' in msg_data:\n",
    "                opportunities.append({\n",
    "                    'subject': \"No Subject\",\n",
    "                    'online_link': \"NOT AVAILABLE\",\n",
    "                    'event_date': \"NOT AVAILABLE\",\n",
    "                    'agency': \"NOT AVAILABLE\",\n",
    "                    'reference': \"NOT AVAILABLE\",\n",
    "                    'contact': \"NOT AVAILABLE\",\n",
    "                    'raw_subject': \"No Subject\",\n",
    "                    'extraction_error': msg_data['error']\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            headers = msg_data.get('payload', {}).get('headers', [])\n",
    "            \n",
    "            # Decode subject header with MIME encoding support\n",
    "            raw_subject = \"No Subject\"\n",
    "            for header in headers:\n",
    "                if header['name'].lower() == 'subject':\n",
    "                    decoded = email.header.decode_header(header['value'])\n",
    "                    subject_parts = []\n",
    "                    for part, encoding in decoded:\n",
    "                        if isinstance(part, bytes):\n",
    "                            encoding = encoding or 'utf-8'\n",
    "                            try:\n",
    "                                subject_parts.append(part.decode(encoding))\n",
    "                            except (UnicodeDecodeError, LookupError):\n",
    "                                subject_parts.append(part.decode('utf-8', errors='replace'))\n",
    "                        else:\n",
    "                            subject_parts.append(part)\n",
    "                    raw_subject = ''.join(subject_parts)\n",
    "                    break\n",
    "\n",
    "            body = get_email_body(msg_data.get('payload', {}))\n",
    "\n",
    "            if raw_subject == \"New RfP mail\":\n",
    "                details = process_new_rfp_mail(raw_subject, body)\n",
    "            else:\n",
    "                if raw_subject == \"New RfP From Bid Mail\" and body in [\"No body content available.\", \"\"]:\n",
    "                    details = process_no_body_rfp_email(raw_subject)\n",
    "                else:\n",
    "                    details = extract_fields(body, raw_subject)\n",
    "                \n",
    "                # Apply new subject logic if title is present and original subject is \"No Subject\"\n",
    "                if details['subject'] == \"No Subject\" and details.get('title'):\n",
    "                    raw_subject = f\"{details.get('title', 'Opportunity Details')}\"\n",
    "\n",
    "                # Fallback to preserve original subject if it becomes \"No Subject\" based on online link\n",
    "                online_link = details['online_link']\n",
    "                if details['subject'] == \"No Subject\" and online_link != \"NOT AVAILABLE\":\n",
    "                    if any(link in online_link for link in [\n",
    "                        \"sam.gov\",\n",
    "                        \"dibbs.bsm.dla.mil\",\n",
    "                        \"passport.cityofnewyork.us\"\n",
    "                    ]):\n",
    "                        details['subject'] = clean_subject(raw_subject, body)\n",
    "\n",
    "                # Skip opportunities where both online_link and reference are \"NOT AVAILABLE\"\n",
    "                if details['online_link'] == \"NOT AVAILABLE\" and details['reference'] == \"NOT AVAILABLE\":\n",
    "                    data_skip_count += 1\n",
    "                    error_msg = \"Skipped: Missing both online link and reference\"\n",
    "                    print(f\"‚ö†Ô∏è {error_msg} for message {msg_id}\")\n",
    "                    details['extraction_error'] = error_msg\n",
    "                    opportunities.append({\n",
    "                        'subject': details['subject'],\n",
    "                        'online_link': details['online_link'],\n",
    "                        'event_date': details['event_date'],\n",
    "                        'agency': details['agency'],\n",
    "                        'reference': details['reference'],\n",
    "                        'contact': details['contact'],\n",
    "                        'raw_subject': raw_subject,\n",
    "                        'extraction_error': details['extraction_error']\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                # Modified deduplication logic: Check for duplicate link, reference, and due date\n",
    "                if online_link != \"NOT AVAILABLE\":\n",
    "                    if details['reference'] != \"NOT AVAILABLE\":\n",
    "                        link_ref_pair = (online_link, details['reference'])\n",
    "                    else:\n",
    "                        link_ref_pair = (online_link, details['event_date'])\n",
    "                    \n",
    "                    if link_ref_pair in seen_link_ref_pairs:\n",
    "                        dedup_skip_count += 1\n",
    "                        error_msg = \"Duplicate Opportunity (based on link and reference or due date)\"\n",
    "                        # print(f\"‚ö†Ô∏è {error_msg} for message {msg_id}\")\n",
    "                        details['extraction_error'] = error_msg\n",
    "                        opportunities.append({\n",
    "                            'subject': details['subject'],\n",
    "                            'online_link': details['online_link'],\n",
    "                            'event_date': details['event_date'],\n",
    "                            'agency': details['agency'],\n",
    "                            'reference': details['reference'],\n",
    "                            'contact': details['contact'],\n",
    "                            'raw_subject': raw_subject,\n",
    "                            'extraction_error': details['extraction_error']\n",
    "                        })\n",
    "                        continue\n",
    "                    seen_link_ref_pairs.add(link_ref_pair)\n",
    "\n",
    "                if all(details[field] == \"NOT AVAILABLE\" for field in ['online_link', 'event_date', 'agency', 'reference', 'contact']):\n",
    "                    data_skip_count += 1\n",
    "                    error_msg = \"No meaningful data extracted\"\n",
    "                    print(f\"‚ö†Ô∏è {error_msg} for message {msg_id}\")\n",
    "                    details['extraction_error'] = error_msg\n",
    "                    opportunities.append({\n",
    "                        'subject': details['subject'],\n",
    "                        'online_link': details['online_link'],\n",
    "                        'event_date': details['event_date'],\n",
    "                        'agency': details['agency'],\n",
    "                        'reference': details['reference'],\n",
    "                        'contact': details['contact'],\n",
    "                        'raw_subject': raw_subject,\n",
    "                        'extraction_error': details['extraction_error']\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                # Deduplication based on key fields\n",
    "                opportunity_key = (\n",
    "                    details['online_link'],\n",
    "                    details['reference'],\n",
    "                    details['event_date'],\n",
    "                    details['agency']\n",
    "                )\n",
    "                if opportunity_key in seen_opportunities:\n",
    "                    dedup_skip_count += 1\n",
    "                    error_msg = \"Duplicate opportunity\"\n",
    "                    print(f\"‚ö†Ô∏è {error_msg} for message {msg_id}\")\n",
    "                    details['extraction_error'] = error_msg\n",
    "                else:\n",
    "                    seen_opportunities.add(opportunity_key)\n",
    "\n",
    "                opportunities.append({\n",
    "                    'subject': details['subject'],\n",
    "                    'online_link': details['online_link'],\n",
    "                    'event_date': details['event_date'],\n",
    "                    'agency': details['agency'],\n",
    "                    'reference': details['reference'],\n",
    "                    'contact': details['contact'],\n",
    "                    'raw_subject': raw_subject,\n",
    "                    'extraction_error': details['extraction_error']\n",
    "                })\n",
    "\n",
    "        current_date = get_current_date_from_calendar(calendar_service)\n",
    "        active_events, expired_events, unparsed_events = categorize_events(opportunities, current_date)\n",
    "        \n",
    "        # Check and send alerts if triggered by scheduler\n",
    "        if run_alerts:\n",
    "            check_and_send_alerts(gmail_service, active_events, current_date)\n",
    "            return  # Exit early to avoid printing tables during scheduled runs\n",
    "\n",
    "        print(f\"\\nüö´ Filtered {google_service_count} Google service emails\")\n",
    "        print(f\"üö´ Filtered {daily_bids_count} Daily Bids Alert emails\")\n",
    "        print(f\"‚ö†Ô∏è Skipped {api_error_count} emails due to API errors\")\n",
    "        print(f\"‚ö†Ô∏è Skipped {dedup_skip_count} emails due to deduplication\")\n",
    "        print(f\"‚ö†Ô∏è Skipped {data_skip_count} emails due to missing data\")\n",
    "        print(f\"üìã Processed {len(opportunities)} opportunities\")\n",
    "        print(\"üïí Timezone: America/New_York\")\n",
    "        \n",
    "        display_events_table(active_events, \"üü¢ ACTIVE RFP OPPORTUNITIES \", True)\n",
    "        display_events_table(expired_events, \"üî¥ RECENTLY EXPIRED RFPs (Last 90 days only)\", False)\n",
    "        display_events_table(unparsed_events, \"üü° RFPs WITH MISSING OR UNPARSED DATES\", False)\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"‚ùå An error occurred: {error}\")\n",
    "\n",
    "def get_current_date_from_calendar(calendar_service: build) -> datetime:\n",
    "    \"\"\"Gets the current date from Google Calendar, normalized to midnight (day 0).\"\"\"\n",
    "    ny_tz = pytz.timezone('America/New_York')\n",
    "    now = datetime.now(ny_tz)\n",
    "    return ny_tz.localize(datetime(now.year, now.month, now.day, 0, 0, 0))\n",
    "\n",
    "def get_email_body(payload: dict) -> str:\n",
    "    \"\"\"Extracts the email body content.\"\"\"\n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            if part['mimeType'] in ['text/plain', 'text/html']:\n",
    "                return base64.urlsafe_b64decode(part['body']['data']).decode('utf-8', errors=\"ignore\")\n",
    "            body = get_email_body(part)\n",
    "            if body:\n",
    "                return body\n",
    "    if 'body' in payload and 'data' in payload['body']:\n",
    "        return base64.urlsafe_b64decode(payload['body']['data']).decode('utf-8', errors=\"ignore\")\n",
    "    return \"No body content available.\"\n",
    "\n",
    "def clean_subject(subject: str, body: str) -> str:\n",
    "    \"\"\"Clean subject line, removing unwanted prefixes and date info, with body fallback.\"\"\"\n",
    "    prefixes = ['Fwd:', 'FW:', 'RE:']\n",
    "    for prefix in prefixes:\n",
    "        subject = re.sub(f'^{prefix}\\\\s*', '', subject, flags=re.IGNORECASE)\n",
    "    subject = re.sub(r'\\bdue\\b\\s*[-:]\\s*(\\d{1,2}/\\d{1,2}/\\d{4}|[A-Za-z]{3}\\s+\\d{1,2},\\s+\\d{4}|.*\\d{4}).*$',\n",
    "                     '', subject, flags=re.IGNORECASE)\n",
    "    date_patterns = [\n",
    "        r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b',\n",
    "        r'\\b[A-Za-z]{3},\\s+[A-Za-z]{3}\\s+\\d{1,2}(?:st|nd|rd|th)?\\s+\\d{4},\\s+\\d{02}:\\d{02}\\b',\n",
    "        r'\\b\\d{4}-\\d{2}-\\d{2}\\b'\n",
    "    ]\n",
    "    for pattern in date_patterns:\n",
    "        subject = re.sub(pattern, '', subject, flags=re.IGNORECASE)\n",
    "    subject = re.sub(r'\\s+', ' ', subject).strip()\n",
    "    subject = re.sub(r'[.,;:!?-]+$', '', subject)\n",
    "    if not subject or subject == \"No Subject\":\n",
    "        if body and body != \"No body content available.\":\n",
    "            lines = body.split('\\n')\n",
    "            for line in lines[:5]:\n",
    "                line = line.strip()\n",
    "                if line and len(line) > 5 and not line.startswith(('http', 'Agency', 'Reference', 'Contact', 'Due')):\n",
    "                    return re.sub(r'\\s+', ' ', line)[:50]\n",
    "        return \"Untitled Opportunity\"\n",
    "    return subject if subject else \"Untitled Opportunity\"\n",
    "\n",
    "def is_google_service_email(headers: List[Dict[str, str]]) -> bool:\n",
    "    \"\"\"Check if email is from Google services.\"\"\"\n",
    "    google_domains = [\n",
    "        'google.com',\n",
    "        'googleapis.com',\n",
    "        'gmail.com',\n",
    "        'accounts.google.com',\n",
    "        'mail.google.com'\n",
    "    ]\n",
    "    google_subject_keywords = [\n",
    "        'Google Account',\n",
    "        'Gmail',\n",
    "        'Google Security',\n",
    "        'Google Workspace',\n",
    "        'Google Cloud'\n",
    "    ]\n",
    "    from_header = next((h['value'] for h in headers if h['name'] == 'From'), '')\n",
    "    if any(domain in from_header for domain in google_domains):\n",
    "        return True\n",
    "    subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '').lower()\n",
    "    if any(keyword.lower() in subject for keyword in google_subject_keywords):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_daily_bids_alert_email(headers: List[Dict[str, str]]) -> bool:\n",
    "    \"\"\"Check if email is a Daily or Weekly Bids Alert.\"\"\"\n",
    "    subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '').lower()\n",
    "    bids_patterns = [\n",
    "        r'\\bdaily\\s*bids?\\s*alert\\b',\n",
    "        r'\\bweekly\\s*bids?\\s*alert\\b',\n",
    "        r'\\bbids?\\s*alert\\b',\n",
    "        r'\\bbid\\s*digest\\b',\n",
    "        r'\\bbid\\s*summary\\b',\n",
    "        r'\\bbid\\s*notification\\b'\n",
    "    ]\n",
    "    return any(re.search(pattern, subject, re.IGNORECASE) for pattern in bids_patterns)\n",
    "\n",
    "def extract_fields(body: str, subject: str) -> Dict[str, str]:\n",
    "    \"\"\"Extracts and cleans all relevant fields from email content.\"\"\"\n",
    "    result = {\n",
    "        'online_link': \"NOT AVAILABLE\",\n",
    "        'event_date': \"NOT AVAILABLE\",\n",
    "        'agency': \"NOT AVAILABLE\",\n",
    "        'reference': \"NOT AVAILABLE\",\n",
    "        'contact': \"NOT AVAILABLE\",\n",
    "        'extraction_error': None,\n",
    "        'subject': clean_subject(subject, body)\n",
    "    }\n",
    "    is_forwarded = subject.lower().startswith(('fwd:', 'fw:'))\n",
    "    if is_forwarded:\n",
    "        result['event_date'] = extract_due_date_from_subject(subject)\n",
    "    if body not in [\"No body content available.\", \"\"]:\n",
    "        body = re.sub(r'<[^>]+>', '', body)\n",
    "        body = re.sub(r'\\s+', ' ', body).strip()\n",
    "        result['online_link'] = extract_url_from_body(body)\n",
    "        if result['event_date'] == \"NOT AVAILABLE\":\n",
    "            date_patterns = [\n",
    "                r'(\\w{3}, \\w{3} \\d{1,2}(?:st|nd|rd|th)? \\d{4}, \\d{02}:\\d{02})',\n",
    "                r'(\\w{3} \\d{1,2}, \\d{4} at \\d{1,2}:\\d{02} [AP]M)',\n",
    "                r'(\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{02})',\n",
    "                r'DUE\\s*-\\s*(\\w{3}, \\w{3} \\d{1,2}, \\d{4})',\n",
    "                r'due\\s*-\\s*(\\w{3}, \\w{3} \\d{1,2}, \\d{4})',\n",
    "                r'(\\w{3}\\s+\\d{1,2}, \\d{4}\\s+at\\s+\\d{1,2}:\\d{02}\\s*[AP]M)',\n",
    "                r'(\\d{1,2}/\\d{1,2}/\\d{4}\\s+\\d{1,2}:\\d{02}(?::\\d{02})?\\s*[AP]M)'\n",
    "            ]\n",
    "            for pattern in date_patterns:\n",
    "                match = re.search(pattern, body, re.IGNORECASE)\n",
    "                if match:\n",
    "                    result['event_date'] = format_extracted_date(match.group(1))\n",
    "                    break\n",
    "    else:\n",
    "        result['event_date'] = extract_due_date_from_subject(subject)\n",
    "    ref_contact = extract_reference_and_contact(body, subject)\n",
    "    result['reference'] = ref_contact['reference']\n",
    "    result['contact'] = ref_contact['contact']\n",
    "    result['agency'] = ref_contact['agency'] if ref_contact['agency'] != \"NOT AVAILABLE\" else clean_agency_name(\"\", subject)\n",
    "    return result\n",
    "\n",
    "def extract_due_date_from_subject(subject: str) -> str:\n",
    "    \"\"\"Enhanced date extraction with comprehensive pattern matching.\"\"\"\n",
    "    subject = subject.strip()\n",
    "    patterns = [\n",
    "        r'(?:DUE|due|Due)[\\s:-]*(?:date\\s+is|date:?)[\\s-]*([A-Za-z]{3},\\s*[A-Za-z]{3}\\s+\\d{1,2}(?:st|nd|rd|th)?\\s+\\d{4},\\s*\\d{02}:\\d{02})',\n",
    "        r'(?:DUE|due|Due)[\\s:-]*(?:date|date:)[\\s-]*(\\d{1,2}/\\d{1,2}/\\d{4}\\s+\\d{1,2}:\\d{02}(?::\\d{02})?\\s*[AP]M)',\n",
    "        r'(?:DUE|due|Due)[\\s:-]*(?:date|date:)?[\\s-]*([A-Za-z]{3}\\s+\\d{1,2}(?:st|nd|rd|th)?\\s+\\d{4})',\n",
    "        r'(?:DUE|due|Due)[\\s:-]*(?:date|date:)?[\\s-]*(\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})',\n",
    "        r'(?:DUE|due|Due)[\\s:-]*(?:date|date:)?[\\s-]*([A-Za-z]{3},\\s*[A-Za-z]{3}\\s+\\d{1,2}(?:st|nd|rd|th)?\\s+\\d{4})',\n",
    "        r'(?:DUE|due|Due)\\s*[-:]\\s*([A-Za-z]{3}\\s+\\d{1,2},\\s+\\d{4})',\n",
    "        r'(?:DUE|due|Due)\\s*[-:]\\s*(\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})',\n",
    "        r'(?:DUE|due|Due)\\s*[-:]\\s*(\\d{1,2}/\\d{1,2}/\\d{4})',\n",
    "        r'\\b(?:closing|submit|deadline|due)\\s*(?:date|by)?\\s*[-:]\\s*([A-Za-z]{3}\\s+\\d{1,2},\\s+\\d{4})',\n",
    "        r'\\b(?:closing|submit|deadline|due)\\s*(?:date|by)?\\s*[-:]\\s*(\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})',\n",
    "        r'\\b(?:closing|submit|deadline|due)\\s*(?:date|by)?\\s*[-:]\\s*(\\d{1,2}/\\d{1,2}/\\d{4})',\n",
    "        r'\\b([A-Za-z]{3},\\s+[A-Za-z]{3}\\s+\\d{1,2}\\s+\\d{4},\\s+\\d{02}:\\d{02})\\b',\n",
    "        r'\\b([A-Za-z]{3}\\s+\\d{1,2},\\s+\\d{4}\\s+at\\s+\\d{1,2}:\\d{02}\\s*[AP]M)\\b',\n",
    "        r'\\b([A-Za-z]{3}\\s+\\d{1,2},\\s+\\d{4})\\b',\n",
    "        r'\\b(\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})\\b',\n",
    "        r'\\b(\\d{1,2}/\\d{1,2}/\\d{4})\\b',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, subject, re.IGNORECASE)\n",
    "        if match:\n",
    "            date_str = match.group(1)\n",
    "            date_str = re.sub(r'(st|nd|rd|th)', '', date_str)\n",
    "            date_str = re.sub(r'^u\\s*,', '', date_str, flags=re.IGNORECASE)\n",
    "            date_str = re.sub(r'\\s+', ' ', date_str).strip()\n",
    "            formatted_date = format_extracted_date(date_str)\n",
    "            if formatted_date != \"NOT AVAILABLE\":\n",
    "                return formatted_date\n",
    "    return \"NOT AVAILABLE\"\n",
    "\n",
    "def format_extracted_date(date_str: str) -> str:\n",
    "    \"\"\"Formats extracted date string into standard format with improved parsing.\"\"\"\n",
    "    logging.debug(f\"Attempting to parse date: {date_str}\")\n",
    "    try:\n",
    "        date_str = re.sub(r'[^\\w\\s/:,-]', '', date_str)\n",
    "        date_str = re.sub(r'\\s+', ' ', date_str).strip()\n",
    "        date_str = re.sub(r'(st|nd|rd|th)', '', date_str, flags=re.IGNORECASE)\n",
    "        date_str = re.sub(r'^u\\s*,', '', date_str, flags=re.IGNORECASE)\n",
    "        dt = parse_date(date_str, fuzzy=True)\n",
    "        formatted = dt.strftime('%a, %b %d %Y, %H:%M')\n",
    "        logging.debug(f\"Formatted date: {formatted}\")\n",
    "        return formatted\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to parse date: {date_str}, error: {str(e)}\")\n",
    "        return \"NOT AVAILABLE\"\n",
    "\n",
    "def extract_url_from_body(body: str) -> str:\n",
    "    \"\"\"Extracts URL from body excluding govdirections URLs.\"\"\"\n",
    "    if body == \"No body content available.\":\n",
    "        return \"NOT AVAILABLE\"\n",
    "    url_pattern = r'(https?://[^\\s\\'\">]+)'\n",
    "    matches = re.findall(url_pattern, body, re.IGNORECASE)\n",
    "    for url in matches:\n",
    "        url = url.strip()\n",
    "        url = re.sub(r'[.,;:!?)\\]\\s]+$', '', url)\n",
    "        url = re.sub(r'Event$', '', url, flags=re.IGNORECASE)\n",
    "        if 'govdirections' not in url.lower() and re.match(r'^https?://[^\\s/$.?#].[^\\s]*$', url):\n",
    "            return url\n",
    "    return \"NOT AVAILABLE\"\n",
    "\n",
    "def extract_reference_and_contact(body: str, subject: str) -> Dict[str, str]:\n",
    "    \"\"\"Extracts reference, contact, and agency from both body and subject.\"\"\"\n",
    "    result = {\n",
    "        'reference': extract_reference_from_subject(subject),\n",
    "        'contact': \"NOT AVAILABLE\",\n",
    "        'agency': \"NOT AVAILABLE\"\n",
    "    }\n",
    "    if body not in [\"No body content available.\", \"\"]:\n",
    "        block_match = re.search(\n",
    "            r'The agency sponsor is:\\s*(.*?)?\\s*The reference for this notice \\(if available\\):\\s*(.*?)\\s*Agency Contact Information:\\s*(.*?)(?:\\n|$)',\n",
    "            body,\n",
    "            re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if block_match:\n",
    "            agency = block_match.group(1).strip()\n",
    "            if agency:\n",
    "                result['agency'] = clean_agency_name(agency, subject)\n",
    "            reference = block_match.group(2).strip()\n",
    "            if reference and is_valid_reference(reference):\n",
    "                result['reference'] = reference\n",
    "            contact = block_match.group(3).strip()\n",
    "            phone_match = re.search(r'(\\d{3}-\\d{3}-\\d{4})', contact)\n",
    "            if phone_match:\n",
    "                digits = re.sub(r'\\D', '', phone_match.group(1))\n",
    "                if len(digits) == 10:\n",
    "                    result['contact'] = f\"{digits[:3]}-{digits[3:6]}-{digits[6:]}\"\n",
    "        if result['contact'] == \"NOT AVAILABLE\":\n",
    "            phone_match = re.search(r'Agency Contact Information:\\s*(\\d{3}-\\d{3}-\\d{4})', body, re.IGNORECASE)\n",
    "            if phone_match:\n",
    "                digits = re.sub(r'\\D', '', phone_match.group(1))\n",
    "                if len(digits) == 10:\n",
    "                    result['contact'] = f\"{digits[:3]}-{digits[3:6]}-{digits[6:]}\"\n",
    "    return result\n",
    "\n",
    "def clean_agency_name(agency_text: str, subject: str) -> str:\n",
    "    \"\"\"Cleans agency names with fallback to subject extraction.\"\"\"\n",
    "    if agency_text:\n",
    "        agency_text = re.split(r'(?:\\bthe\\b|\\breference\\b|\\bnotice\\b|\\bcontact\\b|\\brfp\\b|\\bbid\\b|\\bsolicitation\\b)',\n",
    "                              agency_text, flags=re.IGNORECASE)[0]\n",
    "        agency_text = re.sub(r'[^a-zA-Z0-9\\s,&-]+$', '', agency_text).strip()\n",
    "        agency_text = re.sub(r'\\d{3}-\\d{3}-\\d{4}', '', agency_text).strip()\n",
    "        if agency_text:\n",
    "            return agency_text[:40] + (\"...\" if len(agency_text) > 40 else \"\")\n",
    "    agency = re.sub(r'^(Fwd:\\s*|RE:\\s*|RFP\\s*|Bid\\s*|Solicitation\\s*)', '', subject, flags=re.IGNORECASE)\n",
    "    agency = re.sub(r'-\\s*due\\s*.*$', '', agency, flags=re.IGNORECASE).strip()\n",
    "    return agency[:40] + (\"...\" if len(agency) > 40 else \"\") if agency else \"NOT AVAILABLE\"\n",
    "\n",
    "def extract_reference_from_subject(subject: str) -> str:\n",
    "    \"\"\"Extracts reference number from email subject.\"\"\"\n",
    "    ref_patterns = [\n",
    "        r'RFP\\s*#?([A-Z0-9-]{3,50})\\b',\n",
    "        r'Bid\\s*#?([A-Z0-9-]{3,50})\\b',\n",
    "        r'Solicitation\\s*#?([A-Z0-9-]{3,50})\\b',\n",
    "        r'Ref\\s*#?([A-Z0-9-]{3,50})\\b',\n",
    "        r'#([A-Z0-9-]{3,50})\\b',\n",
    "        r'\\b([A-Z]{2,5}\\d{3,8}-?\\d{0,5})\\b'\n",
    "    ]\n",
    "    for pattern in ref_patterns:\n",
    "        match = re.search(pattern, subject, re.IGNORECASE)\n",
    "        if match and is_valid_reference(match.group(1)):\n",
    "            return match.group(1).upper()\n",
    "    return \"NOT AVAILABLE\"\n",
    "\n",
    "def is_valid_reference(ref: str) -> bool:\n",
    "    \"\"\"Validate if extracted reference meets requirements.\"\"\"\n",
    "    if not ref or not isinstance(ref, str) or ref.upper() == \"NOT AVAILABLE\":\n",
    "        return False\n",
    "    invalid_patterns = [\n",
    "        r'Agency-Contact-Information',\n",
    "        r'Learn-to-Do-Business',\n",
    "        r'Summary-Information',\n",
    "        r'Competitive-Intelligence',\n",
    "        r'Regards----Rashi',\n",
    "        r'\\d{3}-\\d{3}-\\d{4}',\n",
    "        r'^https?://',\n",
    "        r'^www\\.',\n",
    "        r'^event',\n",
    "        r'^view',\n",
    "        r'^s/'\n",
    "    ]\n",
    "    for pattern in invalid_patterns:\n",
    "        if re.search(pattern, ref, re.IGNORECASE):\n",
    "            return False\n",
    "    if len(ref) <= 5 and ref.isupper() and ref.isalpha():\n",
    "        return False\n",
    "    return bool(\n",
    "        3 <= len(ref) <= 50 and\n",
    "        not ref.startswith(('http', 'www', 'event', 'view', 's/')) and\n",
    "        any(char.isalnum() for char in ref)\n",
    "    )\n",
    "\n",
    "def categorize_events(opportunities: List[Dict], current_date: datetime) -> Tuple[List, List, List]:\n",
    "    \"\"\"Categorizes events into active, expired, and unparsed tables, ignoring non-IT keywords for active events.\"\"\"\n",
    "    active_events = []\n",
    "    expired_events = []\n",
    "    unparsed_events = []\n",
    "    ny_tz = pytz.timezone('America/New_York')\n",
    "    \n",
    "    # Non-IT keywords to ignore for active events\n",
    "    non_it_keywords = [\n",
    "        'emergency',\n",
    "        'licenses/support',\n",
    "        'vehicle',\n",
    "        'service emergency',\n",
    "        'survey',\n",
    "        'services',\n",
    "        'data center',\n",
    "        'earthquake monitoring',\n",
    "        'support services', \n",
    "        'library director', 'legal document', 'fire Extinguisher', 'maintenance', 'sole sources', 'epic trained revenue cycle resources'\n",
    "    ]\n",
    "\n",
    "    for event in opportunities:\n",
    "        event_date_str = event.get('event_date', \"NOT AVAILABLE\")\n",
    "        error = event.get('extraction_error')\n",
    "        if error or event_date_str == \"NOT AVAILABLE\":\n",
    "            unparsed_events.append({\n",
    "                **event,\n",
    "                'reason': error or \"No valid date extracted\"\n",
    "            })\n",
    "            continue\n",
    "        try:\n",
    "            formats = [\n",
    "                '%a, %b %d %Y, %H:%M',\n",
    "                '%b %d %Y, %I:%M %p',\n",
    "                '%a, %b %d %Y',\n",
    "                '%b %d, %Y',\n",
    "                '%m/%d/%Y',\n",
    "                '%d %b %Y',\n",
    "                '%Y-%m-%d'\n",
    "            ]\n",
    "            event_date = None\n",
    "            for fmt in formats:\n",
    "                try:\n",
    "                    event_date = datetime.strptime(event_date_str, fmt)\n",
    "                    logging.debug(f\"Parsed date {event_date_str} with format {fmt}\")\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            if event_date is None:\n",
    "                event_date = parse_date(event_date_str, fuzzy=True)\n",
    "                logging.debug(f\"Parsed date {event_date_str} with dateutil.parser\")\n",
    "            event_date = ny_tz.localize(event_date)\n",
    "            days_difference = (event_date - current_date).days\n",
    "            \n",
    "            # Check for non-IT keywords in subject or agency for active events\n",
    "            is_non_it = False\n",
    "            if days_difference >= 0:\n",
    "                subject_lower = event['subject'].lower()\n",
    "                agency_lower = event['agency'].lower()\n",
    "                for keyword in non_it_keywords:\n",
    "                    if keyword in subject_lower or keyword in agency_lower:\n",
    "                        is_non_it = True\n",
    "                        logging.debug(f\"Skipping active event due to non-IT keyword '{keyword}' in subject or agency: {event['subject']}\")\n",
    "                        break\n",
    "            \n",
    "            if days_difference >= 0 and not is_non_it:\n",
    "                active_events.append({\n",
    "                    **event,\n",
    "                    'days_to_expire': days_difference,\n",
    "                    'formatted_date': event_date.strftime('%Y-%m-%d')\n",
    "                })\n",
    "            elif days_difference < 0 and abs(days_difference) <= 90:\n",
    "                expired_events.append({\n",
    "                    **event,\n",
    "                    'days_expired': abs(days_difference),\n",
    "                    'formatted_date': event_date.strftime('%Y-%m-%d')\n",
    "                })\n",
    "            else:\n",
    "                unparsed_events.append({\n",
    "                    **event,\n",
    "                    'reason': \"Date too far in the past\"\n",
    "                })\n",
    "        except ValueError as e:\n",
    "            unparsed_events.append({\n",
    "                **event,\n",
    "                'reason': f\"Date parsing failed: {str(e)} (input: {event_date_str})\"\n",
    "            })\n",
    "            logging.error(f\"Failed to parse date in categorize_events: {event_date_str}, error: {str(e)}\")\n",
    "    active_events.sort(key=lambda x: x['days_to_expire'])\n",
    "    expired_events.sort(key=lambda x: x['days_expired'])\n",
    "    return active_events, expired_events, unparsed_events\n",
    "\n",
    "def display_events_table(events: List[Dict], title: str, is_active: bool = True) -> None:\n",
    "    \"\"\"Displays events in a well-formatted table.\"\"\"\n",
    "    if not events:\n",
    "        print(f\"\\n{title} (No entries found)\")\n",
    "        return\n",
    "    table_data = []\n",
    "    for event in events:\n",
    "        table_data.append([\n",
    "            event['subject'][:50] + \"...\" if len(event['subject']) > 50 else event['subject'],\n",
    "            event['online_link'],\n",
    "            event.get('formatted_date', event['event_date']),\n",
    "            event['agency'],\n",
    "            event['reference'],\n",
    "            event['contact']\n",
    "        ])\n",
    "    headers = [\n",
    "        \"Subject (50 chars max)\",\n",
    "        \"Online Link\",\n",
    "        \"Due Date\",\n",
    "        \"Agency\",\n",
    "        \"Reference\",\n",
    "        \"Contact\"\n",
    "    ]\n",
    "    print(f\"\\n{title} ({len(events)} found):\")\n",
    "    print(tabulate(\n",
    "        table_data,\n",
    "        headers=headers,\n",
    "        tablefmt=\"grid\",\n",
    "        maxcolwidths=[50, None, 25, 40, 20, 15],\n",
    "        stralign=\"left\"\n",
    "    ))\n",
    "\n",
    "def process_no_body_rfp_email(subject: str) -> Dict[str, str]:\n",
    "    \"\"\"Processes emails with subject 'New RfP From Bid Mail' and no body, extracting fields from subject.\"\"\"\n",
    "    result = {\n",
    "        'subject': clean_subject(subject, \"No body content available.\")[:50] + \"...\" if len(clean_subject(subject, \"No body content available.\")) > 50 else clean_subject(subject, \"No body content available.\"),\n",
    "        'online_link': \"NOT AVAILABLE\",\n",
    "        'event_date': \"NOT AVAILABLE\",\n",
    "        'agency': \"NOT AVAILABLE\",\n",
    "        'reference': \"NOT AVAILABLE\",\n",
    "        'contact': \"NOT AVAILABLE\",\n",
    "        'raw_subject': subject,\n",
    "        'extraction_error': None\n",
    "    }\n",
    "    cleaned_subject = clean_subject(subject, \"No body content available.\")\n",
    "    result['event_date'] = extract_due_date_from_subject(cleaned_subject)\n",
    "    result['reference'] = extract_reference_from_subject(cleaned_subject)\n",
    "    result['agency'] = clean_agency_name(\"\", cleaned_subject)\n",
    "    phone_match = re.search(r'(\\d{3}-\\d{3}-\\d{4})', cleaned_subject)\n",
    "    if phone_match:\n",
    "        digits = re.sub(r'\\D', '', phone_match.group(1))\n",
    "        if len(digits) == 10:\n",
    "            result['contact'] = f\"{digits[:3]}-{digits[3:6]}-{digits[6:]}\"\n",
    "    url_match = re.search(r'(https?://[^\\s\\'\">]+)', cleaned_subject)\n",
    "    if url_match:\n",
    "        url = url_match.group(0).strip()\n",
    "        url = re.sub(r'[.,;:!?)\\]\\s]+$', '', url)\n",
    "        if 'govdirections' not in url.lower() and re.match(r'^https?://[^\\s/$.?#].[^\\s]*$', url):\n",
    "            result['online_link'] = url\n",
    "    if all(value == \"NOT AVAILABLE\" for value in [result['event_date'], result['agency'], result['reference']]):\n",
    "        result['extraction_error'] = \"No meaningful data extracted from subject\"\n",
    "    return result\n",
    "\n",
    "def process_new_rfp_mail(subject: str, body: str) -> Dict[str, str]:\n",
    "    \"\"\"Processes emails with subject 'New RfP mail', extracting fields from table in body.\"\"\"\n",
    "    result = {\n",
    "        'subject': clean_subject(subject, body),\n",
    "        'online_link': \"NOT AVAILABLE\",\n",
    "        'event_date': \"NOT AVAILABLE\",\n",
    "        'agency': \"NOT AVAILABLE\",\n",
    "        'reference': \"NOT AVAILABLE\",\n",
    "        'contact': \"NOT AVAILABLE\",\n",
    "        'raw_subject': subject,\n",
    "        'extraction_error': None\n",
    "    }\n",
    "    if body in [\"No body content available.\", \"\"]:\n",
    "        result['extraction_error'] = \"No body content available\"\n",
    "        return result\n",
    "    body = re.sub(r'<[^>]+>', '', body)\n",
    "    body = re.sub(r'\\s+', ' ', body).strip()\n",
    "    table_pattern = r'Subject \\(50 chars max\\)\\s*\\|([^\\|]*)\\|\\s*Online Link\\s*\\|([^\\|]*)\\|\\s*Event Date\\s*\\|([^\\|]*)\\|\\s*Agency\\s*\\|([^\\|]*)\\|\\s*Reference\\s*\\|([^\\|]*)\\|\\s*Contact\\s*\\|([^\\|]*)\\|'\n",
    "    table_match = re.search(table_pattern, body, re.IGNORECASE)\n",
    "    if table_match:\n",
    "        result['subject'] = table_match.group(1).strip()[:50]\n",
    "        result['online_link'] = table_match.group(2).strip()\n",
    "        result['event_date'] = format_extracted_date(table_match.group(3).strip())\n",
    "        result['agency'] = table_match.group(4).strip()[:40]\n",
    "        result['reference'] = table_match.group(5).strip()\n",
    "        result['contact'] = table_match.group(6).strip()\n",
    "        if result['online_link'] and not re.match(r'^https?://[^\\s/$.?#].[^\\s]*$', result['online_link']):\n",
    "            result['online_link'] = \"NOT AVAILABLE\"\n",
    "        if result['contact'] and not re.match(r'\\d{3}-\\d{3}-\\d{4}', result['contact']):\n",
    "            result['contact'] = \"NOT AVAILABLE\"\n",
    "        if result['reference'] and not is_valid_reference(result['reference']):\n",
    "            result['reference'] = \"NOT AVAILABLE\"\n",
    "        if not result['agency']:\n",
    "            result['agency'] = clean_agency_name(\"\", subject)\n",
    "    else:\n",
    "        result['online_link'] = extract_url_from_body(body)\n",
    "        date_patterns = [\n",
    "            r'(\\w{3}, \\w{3} \\d{1,2}(?:st|nd|rd|th)? \\d{4}, \\d{02}:\\d{02})',\n",
    "            r'(\\w{3} \\d{1,2}, \\d{4} at \\d{1,2}:\\d{02} [AP]M)',\n",
    "            r'(\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{02})',\n",
    "            r'DUE\\s*-\\s*(\\w{3}, \\w{3} \\d{1,2}, \\d{4})',\n",
    "            r'due\\s*-\\s*(\\w{3}, \\w{3} \\d{1,2}, \\d{4})',\n",
    "            r'(\\w{3}\\s+\\d{1,2}, \\d{4}\\s+at\\s+\\d{1,2}:\\d{02}\\s*[AP]M)',\n",
    "            r'(\\d{1,2}/\\d{1,2}/\\d{4}\\s+\\d{1,2}:\\d{02}(?::\\d{02})?\\s*[AP]M)'\n",
    "        ]\n",
    "        for pattern in date_patterns:\n",
    "            match = re.search(pattern, body, re.IGNORECASE)\n",
    "            if match:\n",
    "                result['event_date'] = format_extracted_date(match.group(1))\n",
    "                break\n",
    "        ref_contact = extract_reference_and_contact(body, subject)\n",
    "        result['reference'] = ref_contact['reference']\n",
    "        result['contact'] = ref_contact['contact']\n",
    "        result['agency'] = ref_contact['agency'] if ref_contact['agency'] != \"NOT AVAILABLE\" else clean_agency_name(\"\", subject)\n",
    "        result['extraction_error'] = \"No table found, used fallback extraction\"\n",
    "    if all(value == \"NOT AVAILABLE\" for value in [result['online_link'], result['event_date'], result['agency'], result['reference'], result['contact']]):\n",
    "        result['extraction_error'] = \"No meaningful data extracted\"\n",
    "    return result\n",
    "\n",
    "def start_http_server():\n",
    "    \"\"\"Starts a simple HTTP server to serve the UI and JSON data.\"\"\"\n",
    "    class CustomHandler(http.server.SimpleHTTPRequestHandler):\n",
    "        def do_GET(self):\n",
    "            if self.path == '/':\n",
    "                self.send_response(200)\n",
    "                self.send_header('Content-type', 'text/html')\n",
    "                self.end_headers()\n",
    "                self.wfile.write(HTML_CONTENT.encode('utf-8'))\n",
    "            elif self.path == '/rfp_due_today.json':\n",
    "                try:\n",
    "                    with open('rfp_due_today.json', 'rb') as f:\n",
    "                        self.send_response(200)\n",
    "                        self.send_header('Content-type', 'application/json')\n",
    "                        self.end_headers()\n",
    "                        self.wfile.write(f.read())\n",
    "                except FileNotFoundError:\n",
    "                    self.send_response(404)\n",
    "                    self.send_header('Content-type', 'text/plain')\n",
    "                    self.end_headers()\n",
    "                    self.wfile.write(b\"File not found\")\n",
    "            else:\n",
    "                super().do_GET()\n",
    "\n",
    "    # Start the server in a separate thread\n",
    "    server = socketserver.TCPServer((\"\", HTTP_PORT), CustomHandler)\n",
    "    server_thread = threading.Thread(target=server.serve_forever, daemon=True)\n",
    "    server_thread.start()\n",
    "    print(f\"üåê HTTP server started at http://localhost:{HTTP_PORT}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"üîê Authenticating with Google APIs...\")\n",
    "    gmail_service, calendar_service = authenticate_google()\n",
    "    print(\"üì© Fetching emails from the past year...\")\n",
    "    list_all_emails(gmail_service, calendar_service)\n",
    "    print(\"‚è∞ Starting alert scheduler...\")\n",
    "    run_scheduler(gmail_service, calendar_service)\n",
    "    print(\"üåê Starting HTTP server for UI...\")\n",
    "    start_http_server()\n",
    "    # Keep the main thread alive to allow scheduler and server to run\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(60)  # Keep main thread alive\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"üõë Stopping scheduler and server...\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf07628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
